import streamlit as st
import os
import sys
import subprocess
import time

# ==========================================
# ğŸš¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìë™ ì„¤ì¹˜ (MoviePy)
# ==========================================
try:
    from moviepy import ImageSequenceClip
except ImportError:
    try:
        from moviepy.editor import ImageSequenceClip
    except ImportError:
        st.warning("âš ï¸ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬(moviepy) ì„¤ì¹˜ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "moviepy"])
            st.success("âœ… ì„¤ì¹˜ ì™„ë£Œ! ìë™ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨ë©ë‹ˆë‹¤.")
            time.sleep(2)
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
            st.stop()

import cv2
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from ultralytics import YOLO
import tempfile

# ==========================================
# âš™ï¸ ì„¤ì • (Rich Feature ì „ìš©)
# ==========================================
st.set_page_config(page_title="AI 3-Cushion Referee", page_icon="ğŸ±", layout="wide")

MODEL_PATH = "best_model1_lstm.pth" 
YOLO_PATH = "best.pt"           
TABLE_W, TABLE_H = 1280.0, 720.0        
SEQ_LENGTH = 60                         
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ==========================================
# ğŸ§  Rich ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (ì…ë ¥: 6ì±„ë„)
# ==========================================
class RichLSTM(nn.Module):
    def __init__(self):
        super().__init__()
        # ğŸš¨ ì…ë ¥ ì‚¬ì´ì¦ˆ 6 (x, y, dx, dy, speed, angle)
        self.lstm = nn.LSTM(6, 64, 2, batch_first=True)
        self.relu = nn.ReLU()
        self.fc = nn.Linear(64, 1)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.relu(out[:, -1, :])
        return self.sigmoid(self.fc(out))

@st.cache_resource
def load_models():
    model = RichLSTM()
    try:
        state_dict = torch.load(MODEL_PATH, map_location=device)
        model.load_state_dict(state_dict)
        model.to(device)
        model.eval()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None
        
    yolo = YOLO(YOLO_PATH)
    return model, yolo

# ==========================================
# ğŸ› ï¸ ë°ì´í„° ì „ì²˜ë¦¬ (ìˆ˜êµ¬ ìë™ ê°ì§€ + 6íŠ¹ì§•)
# ==========================================
# def process_data_rich(df):
#     # 1. ê³µ ìƒ‰ê¹”ë³„ë¡œ ë¶„ë¦¬
#     white = df[df['cls'] == 1].copy()
#     yellow = df[df['cls'] == 2].copy()
    
#     # ì†ë„ ê³„ì‚° í•¨ìˆ˜
#     def get_max_speed(ball_df):
#         if len(ball_df) < 5: return 0
#         ball_df = ball_df.sort_values('frame')
#         dx = ball_df['x'].diff().fillna(0)
#         dy = ball_df['y'].diff().fillna(0)
#         return np.sqrt(dx**2 + dy**2).max()

#     w_speed = get_max_speed(white)
#     y_speed = get_max_speed(yellow)
    
#     # ğŸš¨ [ìˆ˜êµ¬ ìë™ ê°ì§€] ë” ë¹ ë¥¸ ê³µì„ ìˆ˜êµ¬ë¡œ ì„ íƒ
#     if w_speed >= y_speed:
#         target, ball_color = white, "White"
#     else:
#         target, ball_color = yellow, "Yellow"

#     if len(target) < 10: return None, None, None

#     # 2. ë³´ê°„ ë° ìŠ¤ë¬´ë”©
#     target = target.sort_values('conf', ascending=False).drop_duplicates('frame').sort_values('frame')
#     target['x'] = target['x'].rolling(window=5, min_periods=1).mean()
#     target['y'] = target['y'].rolling(window=5, min_periods=1).mean()
    
#     min_f, max_f = target['frame'].min(), target['frame'].max()
#     full_range = range(int(min_f), int(max_f) + 1)
#     target = target.set_index('frame').reindex(full_range)
#     target[['x', 'y']] = target[['x', 'y']].interpolate(method='linear')
#     target = target.dropna().reset_index()

#     points_dict = {int(r['frame']): (int(r['x']), int(r['y'])) for _, r in target.iterrows()}

#     # 3. 6ê°€ì§€ íŠ¹ì§• ê³„ì‚° (Rich Feature)
#     x_norm = target['x'].values / TABLE_W
#     y_norm = target['y'].values / TABLE_H
    
#     dx = np.diff(x_norm, prepend=x_norm[0])
#     dy = np.diff(y_norm, prepend=y_norm[0])
#     speed = np.sqrt(dx**2 + dy**2)
#     angle = np.arctan2(dy, dx) / np.pi 

#     # íƒ€ê²© ì‹œì  ê¸°ì¤€ ìë¥´ê¸°
#     peak_idx = np.argmax(speed)
#     if speed[peak_idx] < 0.005: return None, None, None

#     start_idx = max(0, peak_idx - 5)
#     end_idx = start_idx + SEQ_LENGTH
    
#     features = np.stack([x_norm, y_norm, dx, dy, speed, angle], axis=1)
#     features = features[start_idx : end_idx]

#     # íŒ¨ë”©
#     if len(features) < SEQ_LENGTH:
#         padding = np.zeros((SEQ_LENGTH - len(features), 6))
#         features = np.vstack([features, padding])
        
#     # ì •ê·œí™”
#     mean = features.mean(axis=0)
#     std = features.std(axis=0) + 1e-6
#     features = (features - mean) / std
    
#     return features, points_dict, ball_color

# ==========================================
# ğŸ› ï¸ ë°ì´í„° ì „ì²˜ë¦¬ (ìˆ˜êµ¬ ìë™ ê°ì§€ ê°œì„ íŒ)
# ==========================================
def process_data_rich(df):
    # 1. ê³µ ìƒ‰ê¹”ë³„ë¡œ ë¶„ë¦¬ ë° ì •ë ¬
    white = df[df['cls'] == 1].sort_values('frame')
    yellow = df[df['cls'] == 2].sort_values('frame')
    
    # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] ìˆ˜êµ¬ íŒë³„ ë¡œì§ ë³€ê²½ (ì†ë„ -> ì›€ì§ì„ ì‹œì‘ íƒ€ì´ë°)
    def get_movement_start_frame(ball_df, threshold=2.0):
        if len(ball_df) < 5: return 99999 # ë°ì´í„° ì—†ìœ¼ë©´ ì•„ì£¼ ëŠ¦ì€ ê°’ ë°˜í™˜
        
        # ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•œ ìŠ¤ë¬´ë”© (ì¢Œí‘œ íŠ ë°©ì§€)
        ball_df['x_smooth'] = ball_df['x'].rolling(window=3, min_periods=1).mean()
        ball_df['y_smooth'] = ball_df['y'].rolling(window=3, min_periods=1).mean()
        
        # ì†ë„ ê³„ì‚°
        dx = ball_df['x_smooth'].diff().fillna(0)
        dy = ball_df['y_smooth'].diff().fillna(0)
        speed = np.sqrt(dx**2 + dy**2)
        
        # íŠ¹ì • ì†ë„(threshold)ë¥¼ ë„˜ëŠ” ì²« ë²ˆì§¸ í”„ë ˆì„ ì°¾ê¸°
        moving_frames = ball_df[speed > threshold]['frame']
        if len(moving_frames) > 0:
            return moving_frames.min()
        else:
            return 99999 # ì›€ì§ì„ì´ ê±°ì˜ ì—†ìœ¼ë©´ ë¬´ì‹œ

    # ê°ê° ì–¸ì œ ì²˜ìŒ ì›€ì§ì˜€ëŠ”ì§€ ì²´í¬
    w_start = get_movement_start_frame(white)
    y_start = get_movement_start_frame(yellow)
    
    # ë” ë¨¼ì € ì›€ì§ì¸ ê³µì„ ìˆ˜êµ¬ë¡œ ì„ ì •
    # (ë‘˜ ë‹¤ ì•ˆ ì›€ì§ì˜€ê±°ë‚˜ ë¹„ìŠ·í•˜ë©´ ê¸°ì¡´ëŒ€ë¡œ ë°ì´í„° ë§ì€ ìª½ or í°ìƒ‰ ìš°ì„ )
    if w_start < y_start:
        target, ball_color = white, "White"
    elif y_start < w_start:
        target, ball_color = yellow, "Yellow"
    else:
        # íƒ€ì´ë°ì´ ê°ì§€ ì•ˆë˜ë©´ ë°ì´í„° ê¸¸ì´ë¡œ íŒë‹¨
        if len(white) >= len(yellow):
            target, ball_color = white, "White"
        else:
            target, ball_color = yellow, "Yellow"

    if len(target) < 10: return None, None, None

    # 2. ë³´ê°„ ë° ìŠ¤ë¬´ë”© (ì„ íƒëœ ìˆ˜êµ¬ì— ëŒ€í•´ ì •ë°€ ì‘ì—…)
    target = target.sort_values('conf', ascending=False).drop_duplicates('frame').sort_values('frame')
    target['x'] = target['x'].rolling(window=5, min_periods=1).mean()
    target['y'] = target['y'].rolling(window=5, min_periods=1).mean()
    
    min_f, max_f = target['frame'].min(), target['frame'].max()
    full_range = range(int(min_f), int(max_f) + 1)
    target = target.set_index('frame').reindex(full_range)
    target[['x', 'y']] = target[['x', 'y']].interpolate(method='linear')
    target = target.dropna().reset_index()

    points_dict = {int(r['frame']): (int(r['x']), int(r['y'])) for _, r in target.iterrows()}

    # 3. 6ê°€ì§€ íŠ¹ì§• ê³„ì‚° (Rich Feature)
    x_norm = target['x'].values / TABLE_W
    y_norm = target['y'].values / TABLE_H
    
    dx = np.diff(x_norm, prepend=x_norm[0])
    dy = np.diff(y_norm, prepend=y_norm[0])
    speed = np.sqrt(dx**2 + dy**2)
    angle = np.arctan2(dy, dx) / np.pi 

    # íƒ€ê²© ì‹œì  ê¸°ì¤€ ìë¥´ê¸°
    peak_idx = np.argmax(speed)
    
    # ì†ë„ê°€ ë„ˆë¬´ ëŠë¦¬ë©´(ì •ì§€ ì˜ìƒ ë“±) ë¬´ì‹œ
    if speed[peak_idx] < 0.005: return None, None, None

    start_idx = max(0, peak_idx - 5)
    end_idx = start_idx + SEQ_LENGTH
    
    features = np.stack([x_norm, y_norm, dx, dy, speed, angle], axis=1)
    features = features[start_idx : end_idx]

    # íŒ¨ë”©
    if len(features) < SEQ_LENGTH:
        padding = np.zeros((SEQ_LENGTH - len(features), 6))
        features = np.vstack([features, padding])
        
    # ì •ê·œí™”
    mean = features.mean(axis=0)
    std = features.std(axis=0) + 1e-6
    features = (features - mean) / std
    
    return features, points_dict, ball_color


# ==========================================
# ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë©”ì¸ ë¡œì§
# ==========================================
def process_video(uploaded_file, ai_referee, yolo_model):
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') 
    tfile.write(uploaded_file.read())
    video_path = tfile.name
    tfile.close()

    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    frame_list = []
    while True:
        ret, frame = cap.read()
        if not ret: break
        frame_list.append(frame)
    cap.release()
    
    # YOLO ì¸ì‹ (1ë²ˆ í°ê³µ, 2ë²ˆ ë…¸ë€ê³µ ëª¨ë‘ ìˆ˜ì§‘)
    video_data = []
    for i, frame in enumerate(frame_list):
        results = yolo_model.predict(frame, conf=0.05, verbose=False)
        for r in results:
            for box in r.boxes:
                # ğŸš¨ ì¤‘ìš”: 1(White), 2(Yellow) ëª¨ë‘ ë¦¬ìŠ¤íŠ¸ì— ë‹´ìŒ
                if int(box.cls[0]) in [1, 2]: 
                    x, y, w, h = box.xywh[0].cpu().numpy()
                    video_data.append([i, int(box.cls[0]), x, y, float(box.conf[0])])

    if not video_data: return None, None, None, "ê³µì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    df = pd.DataFrame(video_data, columns=['frame', 'cls', 'x', 'y', 'conf'])
    
    # Rich ì „ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ (ì—¬ê¸°ì„œ ìˆ˜êµ¬ ê²°ì •ë¨)
    input_seq, points_dict, ball_color = process_data_rich(df)
    
    if input_seq is None: return None, None, None, "ìœ íš¨í•œ ê¶¤ì ì´ ì—†ìŠµë‹ˆë‹¤."

    # AI íŒë…
    input_tensor = torch.FloatTensor(input_seq).unsqueeze(0).to(device)
    with torch.no_grad():
        score = ai_referee(input_tensor).item()
    
    result_text = "SUCCESS" if score >= 0.5 else "FAIL"
    color_res = (0, 255, 0) if score >= 0.5 else (0, 0, 255)
    
    # MoviePyìš© í”„ë ˆì„ ìƒì„±
    output_frames = []
    draw_pts = []
    
    for i, frame in enumerate(frame_list):
        if i in points_dict: draw_pts.append(points_dict[i])
        
        # ê·¸ë¦¼ ê·¸ë¦¬ê¸° (OpenCV BGR)
        temp_frame = frame.copy()
        
        # í…ìŠ¤íŠ¸: ê²°ê³¼ + ìˆ˜êµ¬ ìƒ‰ê¹” í‘œì‹œ

        cv2.putText(temp_frame, f"Cue Ball: {ball_color}", 
                   (50, 130), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        if len(draw_pts) > 1:
            pts = np.array(draw_pts, np.int32).reshape((-1, 1, 2))
            cv2.polylines(temp_frame, [pts], False, color_res, 3)
            
        # RGB ë³€í™˜ (MoviePyìš©)
        frame_rgb = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2RGB)
        output_frames.append(frame_rgb)
    
    # ì˜ìƒ ì €ì¥
    timestamp = int(time.time())
    output_filename = f"result_{timestamp}.mp4"
    output_path = os.path.join(os.getcwd(), output_filename)
    
    clip = ImageSequenceClip(output_frames, fps=fps)
    clip.write_videofile(output_path, codec='libx264', audio=False, logger=None, preset='ultrafast')
    
    if os.path.exists(video_path):
        try: os.remove(video_path)
        except: pass
        
    return output_path, result_text, score, None

# ==========================================
# ğŸ–¥ï¸ UI
# ==========================================
st.title("3ì¿ ì…˜ íŒì •(ì˜ˆì¸¡) ì‹œìŠ¤í…œ")

ai_model, yolo_model = load_models()

uploaded_file = st.file_uploader("ë¶„ì„í•  ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "avi"])

if uploaded_file is not None:
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ì›ë³¸ ì˜ìƒ")
        st.video(uploaded_file)
        
    with col2:
        st.subheader("íŒë… ê²°ê³¼")
        if st.button("íŒë… ì‹œì‘"):
            with st.spinner('ë¶„ì„ ë° ìˆ˜êµ¬ ê°ì§€ ì¤‘...'):
                res_path, res_text, score, err = process_video(uploaded_file, ai_model, yolo_model)
                
                if err:
                    st.error(f"ì˜¤ë¥˜: {err}")
                elif res_path and os.path.exists(res_path):
                    if res_text == "SUCCESS":
                        st.success(f"íŒë… ê²°ê³¼: {res_text} ({score*100:.1f}%)")
                    else:
                        st.error(f"íŒë… ê²°ê³¼: {res_text} ({score*100:.1f}%)")
                    
                    # ë°”ì´ë„ˆë¦¬ ì½ê¸° ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    with open(res_path, 'rb') as f:
                        video_bytes = f.read()
                    
                    if len(video_bytes) > 0:
                        st.video(video_bytes, format="video/mp4")
                        st.download_button(
                            label="ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                            data=video_bytes,
                            file_name=os.path.basename(res_path),
                            mime="video/mp4"
                        )
                    else:
                        st.error("ìƒì„±ëœ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("ì˜ìƒ ìƒì„± ì‹¤íŒ¨")